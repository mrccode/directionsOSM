{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyroutelib2.route import Router\n",
    "from pyroutelib2.loadOsm import LoadOsm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "from multiprocessing import Pool, Pipe, Process, Lock\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function counts distance between two geographical coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_between_coordinates(point1, point2):\n",
    "    point2['lat'] = float(point2['lat'])\n",
    "    point2['lon'] = float(point2['lon'])\n",
    "    point1['lat'] = float(point1['lat'])\n",
    "    point1['lon'] = float(point1['lon'])\n",
    "    ky = 40000 / 360\n",
    "    kx = math.cos(math.pi * point2['lat'] / 180.0) * ky\n",
    "    dx = math.fabs(point2['lon'] - point1['lon']) * kx\n",
    "    dy = math.fabs(point2['lat'] - point1['lat']) * ky\n",
    "    return dx * dx + dy * dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load data from two csv files. First should contain list of objects that are the base for our research. In this case this will be real estate transactions in Katowice. Requirement is that it should have lat and lon columns.\n",
    "\n",
    "Second file should contains list of Point of Interest which we look for arround each of the objects from the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(objectsfile, poifile, sep1, sep2):\n",
    "    _objects = pd.read_csv(filepath_or_buffer=objectsfile, sep=sep1)\n",
    "    _pois = pd.read_csv(filepath_or_buffer=poifile, sep=sep2)\n",
    "    return _objects, _pois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a coordinate, this will return list of POIs being within given distance from the object.\n",
    "\n",
    "There definitelly is better way to do it though. One would be to sort the list based on the POIs coordinates and choose only those whose coordinates are around the object's coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_closest_objects(centerPoint, pois, within_distance):\n",
    "    nearpois = []\n",
    "    for ind, row in pois.iterrows():\n",
    "        checkPoint = {\n",
    "            'lat': row['lat'],\n",
    "            'lon': row['lon'],\n",
    "        }\n",
    "        if distance_between_coordinates(centerPoint, checkPoint) < within_distance:\n",
    "            nearpois.append([checkPoint['lat'], checkPoint['lon']])\n",
    "    return nearpois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_pois is a function that search will return number of POIs within given distance from the object plus walking distance from the one being the closest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pois(pois, within_distance, data, router, fprow, pipe_):\n",
    "    centerpoint = {\n",
    "        'lat': float(fprow['lat']),\n",
    "        'lon': float(fprow['lon']),\n",
    "    }\n",
    "    closest_objects = find_closest_objects(centerpoint, pois, within_distance)\n",
    "    distances = []\n",
    "    node1 = data.findNode(float(centerpoint['lat']), float(centerpoint['lon']))\n",
    "    for object_ in closest_objects:\n",
    "        if float(centerpoint['lat']) == object_[0] and float(centerpoint['lon']) == object_[1]:\n",
    "            foundroute = 'success'\n",
    "            routedistance = 0\n",
    "        else:\n",
    "            node2 = data.findNode(object_[0], object_[1])\n",
    "            foundroute, route, routedistance = router.doRoute(node1, node2)\n",
    "        if foundroute == 'success':\n",
    "            print(\"Walking distance: %s\" % routedistance)\n",
    "            distances.append(routedistance)\n",
    "        else:\n",
    "            print(\"Failed (%s)\" % foundroute)\n",
    "    if len(distances) > 0 and min(distances):\n",
    "        fprow['NumberOfPOIs'] = len(distances)\n",
    "        fprow['DistanceToClosesPoi'] = min(distances)\n",
    "        pipe_.send(fprow)\n",
    "        return \"%s %s\" % (len(distances), min(distances))\n",
    "    else:\n",
    "        return \"0 666\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add_distance is function that is ran bye the multiprocessing pool. It modifies the Data Frame so that it includes data about number of sorrounding POIs and distance from the closest one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_distance(df_, pois_, within_distance_, pipe_):\n",
    "    data_ = LoadOsm(\"foot\")\n",
    "    router_ = Router(data_)\n",
    "    df_['NumberOfPOIsAndDistanceToClosestPoi'] = df_.apply(lambda row_:\n",
    "                                                           find_pois(\n",
    "                                                               pois=pois_,\n",
    "                                                               within_distance=within_distance_,\n",
    "                                                               data=data_,\n",
    "                                                               router=router_,\n",
    "                                                               fprow=row_,\n",
    "                                                               pipe_=pipe_\n",
    "                                                           ), axis=1)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculations can take quite some time, especially if the dataset is large. Thus multiprocessing is used to utilize all processors being available. Python multiprocessing pool function is used and it requires a function with single parameter to be called. This is why partial from functools was used later, we need to pass multiple arguments somehow and this is the way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last function is a reader that will read a pipe and save its content to a file every 100 rows are added. The only purpose of it is so that if the program crashesh, hangs or anything else happens to it during computation, the results collected so far are not lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reader(pipeAndLock):\n",
    "    output_p, input_p, lock = pipeAndLock\n",
    "    input_p.close()\n",
    "    rowscount = 0\n",
    "    rows = []\n",
    "    while True:\n",
    "        try:\n",
    "            msg = output_p.recv()\n",
    "            rows.append(msg)\n",
    "            rowscount += 1\n",
    "            if rowscount == 100:\n",
    "                lock.acquire()\n",
    "                with open(\"output.csv\", \"a\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerows(rows)\n",
    "                    del rows[:]\n",
    "                    rowscount = 0\n",
    "                lock.release()\n",
    "        except EOFError:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(rows)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function loads the data, create partial call and initializes computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking distance: 0.7224500872018547\n",
      "Walking distance: 0.2993469272507149\n",
      "Walking distance: 0.786854302908355\n",
      "Walking distance: 0.14770649375276232\n",
      "Walking distance: 0.7224500872018547\n",
      "Walking distance: 0.7224500872018547\n",
      "Walking distance: 0.7224500872018547\n",
      "Walking distance: 0.2993469272507149\n",
      "Walking distance: 0.786854302908355\n",
      "Walking distance: 0.14770649375276232\n",
      "Walking distance: 0.7224500872018547\n",
      "Walking distance: 0.7224500872018547\n",
      "Walking distance: 0.7875279647373605\n",
      "Walking distance: 0.3369849603412221\n",
      "Walking distance: 0.8448942786212982\n",
      "Walking distance: 0.18177061137384434\n",
      "Walking distance: 0.7875279647373605\n",
      "Walking distance: 0.7875279647373605\n",
      "Walking distance: 0.7875279647373605\n",
      "Walking distance: 0.3369849603412221\n",
      "Walking distance: 0.8448942786212982\n",
      "Walking distance: 0.18177061137384434\n",
      "Walking distance: 0.7875279647373605\n",
      "Walking distance: 0.7875279647373605\n",
      "   lp.  Cena.jednostkowa.netto Z.powierzchnia.przynalezna  Data.transakcji  \\\n",
      "0   10                 1975.75                        Nie            42410   \n",
      "1   11                 3460.45                        Nie            42396   \n",
      "2   12                 3257.98                        Tak            42396   \n",
      "\n",
      "                Rodzaj.transakcji     Sprzedajacy        Kupujacy Wojewodztwo  \\\n",
      "0  umowa sprzedazy - rynek wtorny  osoba fizyczna  osoba fizyczna     Slaskie   \n",
      "1  umowa sprzedazy - rynek wtorny  osoba fizyczna  osoba fizyczna     Slaskie   \n",
      "2  umowa sprzedazy - rynek wtorny  osoba fizyczna  osoba fizyczna     Slaskie   \n",
      "\n",
      "     Powiat     Gmina                 ...                   \\\n",
      "0  Katowice  Katowice                 ...                    \n",
      "1  Katowice  Katowice                 ...                    \n",
      "2  Katowice  Katowice                 ...                    \n",
      "\n",
      "  Pow..lokalu.obliczeniowa liczba.pokoi Stan.techniczny.lokalu Rok.budowy  \\\n",
      "0                    53.60            3                    NaN        NaN   \n",
      "1                    42.48            2                    NaN        NaN   \n",
      "2                    45.12            2                    NaN        NaN   \n",
      "\n",
      "   Cena.netto       Adres   X        lon        lat  \\\n",
      "0      105900  1 Maja 144 NaN  19.059507  50.259083   \n",
      "1      147000  1 Maja 148 NaN  19.060313  50.259210   \n",
      "2      147000  1 Maja 148 NaN  19.060313  50.259210   \n",
      "\n",
      "   NumberOfPOIsAndDistanceToClosestPoi  \n",
      "0                6 0.14770649375276232  \n",
      "1                6 0.18177061137384434  \n",
      "2                6 0.18177061137384434  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    num_partitions = 2  # number of partitions to split dataframe\n",
    "    num_cores = 2  # number of cores on your machine\n",
    "\n",
    "    folder = \"/home/mapastec/Documents/studia/KoloNaukowe/dane/\"\n",
    "\n",
    "    objects, pois = load_data(objectsfile=\"%sremaster_lokale.csv\" %folder,\n",
    "                              poifile=\"%sszkolykur.csv\" %folder,\n",
    "                              sep1=',', sep2=';')\n",
    "    within_distance = 1\n",
    "#    data = LoadOsm(\"foot\")\n",
    "#    router = Router(data)\n",
    "    output_p, input_p = Pipe()\n",
    "    lock = Lock()\n",
    "\n",
    "    reader_p = Process(target=reader, args=((output_p, input_p, lock),))\n",
    "    reader_p.start()\n",
    "    output_p.close()\n",
    "\n",
    "    partialAddDistance = partial(add_distance, pois_=pois, within_distance_=within_distance,\n",
    "                                 pipe_=input_p)\n",
    "\n",
    "    outputdf = parallelize_dataframe(objects, partialAddDistance)\n",
    "\n",
    "    print(outputdf.head())\n",
    "    outputdf.to_csv('outputdf.csv', sep=';')\n",
    "    reader_p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
